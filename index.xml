<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>neuralware</title>
<link>https://neuralware.github.io/</link>
<atom:link href="https://neuralware.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.6.42</generator>
<lastBuildDate>Fri, 27 Jun 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>Context Engineering: Building Smarter AI Agents - Part 3/3</title>
  <dc:creator>Prashant Patel</dc:creator>
  <link>https://neuralware.github.io/posts/context-engineering-part-3/</link>
  <description><![CDATA[ 





<section id="best-practices-for-context-engineering-with-langgraph" class="level2">
<h2 class="anchored" data-anchor-id="best-practices-for-context-engineering-with-langgraph">Best Practices for Context Engineering with LangGraph</h2>
<p>In <a href="https://neuralware.github.io/posts/context-engineering-part-1/">Part 1</a> and <a href="https://neuralware.github.io/posts/context-engineering-part-2/">Part 2</a> of this series, we introduced Context Engineering and explored how to use LangGraph to build context-aware AI applications, however, building robust and intelligent LLM applications with LangGraph requires more than just understanding the syntax; it demands a strategic approach to context engineering. Here are some best practices to guide your development:</p>
<section id="define-clear-goals-and-constraints" class="level3">
<h3 class="anchored" data-anchor-id="define-clear-goals-and-constraints">Define Clear Goals and Constraints</h3>
<p>Before you even start coding, clearly articulate what you want your LLM application to achieve. What are its primary functions? What are its limitations? Understanding the scope and purpose will help you identify what context is truly necessary and what is superfluous. For instance, a customer service bot needs different context than a creative writing assistant.</p>
</section>
<section id="curate-and-structure-context" class="level3">
<h3 class="anchored" data-anchor-id="curate-and-structure-context">Curate and Structure Context</h3>
<p>The quality of your LLM’s output is directly proportional to the quality and relevance of the context it receives.</p>
<ul>
<li><strong>Relevance is Key:</strong> Only provide information that is directly pertinent to the current task. Overloading the context window with irrelevant data can lead to confusion, increased token usage, and diminished performance.</li>
<li><strong>Precision Matters:</strong> Ensure the information is accurate and unambiguous. Vague or contradictory context will lead to vague or contradictory responses.</li>
<li><strong>Structure for Clarity:</strong> Present context in a clear, consistent, and structured format. Use JSON, XML, or well-defined Markdown to organise information. This makes it easier for the LLM to parse and extract the necessary details.</li>
<li><strong>Prioritise Information:</strong> If context window limits are a concern, prioritise the most critical information. Techniques like summarisation or hierarchical retrieval can help manage large volumes of data.</li>
</ul>
</section>
<section id="implement-robust-memory-mechanisms" class="level3">
<h3 class="anchored" data-anchor-id="implement-robust-memory-mechanisms">Implement Robust Memory Mechanisms</h3>
<p>Effective memory management is fundamental to maintaining coherent and personalised interactions.</p>
<ul>
<li><strong>Short-term Memory (Conversation History):</strong> For ongoing dialogues, implement strategies to manage conversation history. This might involve:
<ul>
<li><strong>Summarisation:</strong> Periodically summarising past turns to condense the history while retaining key information.</li>
<li><strong>Windowing:</strong> Keeping only the most recent N turns or a fixed number of tokens.</li>
<li><strong>Hybrid Approaches:</strong> Combining summarisation with a sliding window.</li>
</ul></li>
<li><strong>Long-term Memory (Knowledge Bases):</strong> For information that needs to persist across sessions or is too large for the context window, integrate with external knowledge bases. This typically involves:
<ul>
<li><strong>Vector Databases:</strong> Storing embeddings of documents and retrieving relevant chunks based on semantic similarity (as seen in the RAG example).</li>
<li><strong>Traditional Databases:</strong> Storing structured data like user profiles, preferences, or past transactions.</li>
<li><strong>Knowledge Graphs:</strong> Representing complex relationships between entities for more sophisticated retrieval.</li>
</ul></li>
</ul>
</section>
<section id="strategic-tool-integration" class="level3">
<h3 class="anchored" data-anchor-id="strategic-tool-integration">Strategic Tool Integration</h3>
<p>Tools extend the capabilities of your LLM, allowing it to interact with the real world and access up-to-date information.</p>
<ul>
<li><strong>Define Tool Capabilities Clearly:</strong> Ensure your tools have clear, concise descriptions that accurately convey their function to the LLM. The LLM relies on these descriptions to decide when and how to use a tool.</li>
<li><strong>Handle Tool Outputs:</strong> Design your graph to effectively process and integrate tool outputs back into the context. This might involve parsing JSON responses, summarising long text outputs, or handling errors gracefully.</li>
<li><strong>Conditional Tool Use:</strong> Leverage LangGraph’s conditional edges to enable the LLM to dynamically decide whether a tool call is necessary based on the current query and context. This prevents unnecessary tool invocations and improves efficiency.</li>
</ul>
</section>
<section id="iterative-development-and-testing" class="level3">
<h3 class="anchored" data-anchor-id="iterative-development-and-testing">Iterative Development and Testing</h3>
<p>Context engineering is rarely a one-shot process. It requires continuous refinement.</p>
<ul>
<li><strong>Start Simple:</strong> Begin with a basic graph and gradually add complexity. Test each component and connection thoroughly.</li>
<li><strong>Test Edge Cases:</strong> Don’t just test happy paths. Actively try to break your system by providing ambiguous queries, unexpected inputs, or requests that require complex reasoning or tool use.</li>
<li><strong>Monitor Performance:</strong> Track metrics like response time, accuracy, and token usage. Identify bottlenecks or areas where context management can be improved.</li>
</ul>
</section>
<section id="leverage-observability-tools-e.g.-langsmith" class="level3">
<h3 class="anchored" data-anchor-id="leverage-observability-tools-e.g.-langsmith">Leverage Observability Tools (e.g., LangSmith)</h3>
<p>Tools like LangSmith (from the creators of LangChain and LangGraph) are invaluable for debugging and understanding your LLM applications.</p>
<ul>
<li><p><strong>Trace Agent Calls:</strong> LangSmith allows you to visualise the execution flow of your LangGraph application, showing you exactly what context was passed to each node, what the LLM’s thought process was, and what tool calls were made. This is critical for identifying where context might be failing or where the LLM is misinterpreting information.</p></li>
<li><p><strong>Evaluate Context Effectiveness:</strong> Use these traces to evaluate whether the context you are providing is indeed leading to the desired outcomes. Adjust your context engineering strategies based on these insights.</p></li>
</ul>
</section>
</section>
<section id="conclusion-the-future-is-context-aware-ai" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-the-future-is-context-aware-ai">Conclusion: The Future is Context-Aware AI</h2>
<p>It’s clear that the future of AI development, particularly with LLMs, lies beyond simple prompting. It resides in the meticulous design and management of the information environment in which these powerful models operate.</p>
<p><strong>Context engineering</strong> is not merely an optimisation; it is a fundamental shift in how we build intelligent systems. By actively curating, structuring, and dynamically managing the context, we empower LLMs to move from being reactive text generators to proactive, reasoning agents capable of tackling complex, real-world problems with unprecedented accuracy and reliability.</p>
<p><strong>LangGraph</strong> stands out as an indispensable framework in this new paradigm. Its graph-based architecture provides the necessary control and flexibility to orchestrate intricate workflows, manage state across multiple turns, integrate external tools seamlessly, and facilitate sophisticated multi-agent collaborations. It transforms the abstract challenge of context management into a concrete, programmable solution, enabling developers to build truly robust and context-aware AI applications.</p>
<p>As you embark on your journey to build more intelligent and capable LLM applications, remember that the key to unlocking their full potential lies in mastering context. Embrace context engineering, leverage the power of frameworks like LangGraph, and contribute to the exciting future of AI.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{patel2025,
  author = {Patel, Prashant},
  title = {Context {Engineering:} {Building} {Smarter} {AI} {Agents} -
    {Part} 3/3},
  date = {2025-06-27},
  url = {https://neuralware.github.io/posts/context-engineering-part-3/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-patel2025" class="csl-entry quarto-appendix-citeas">
Patel, Prashant. 2025. <span>“Context Engineering: Building Smarter AI
Agents - Part 3/3.”</span> June 27, 2025. <a href="https://neuralware.github.io/posts/context-engineering-part-3/">https://neuralware.github.io/posts/context-engineering-part-3/</a>.
</div></div></section></div> ]]></description>
  <category>AI Agents</category>
  <category>LangGraph</category>
  <category>Context Engineering</category>
  <guid>https://neuralware.github.io/posts/context-engineering-part-3/</guid>
  <pubDate>Fri, 27 Jun 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Context Engineering: Building Smarter AI Agents - Part 2/3</title>
  <dc:creator>Prashant Patel</dc:creator>
  <link>https://neuralware.github.io/posts/context-engineering-part-2/</link>
  <description><![CDATA[ 





<section id="langgraph-your-toolkit-for-context-engineering" class="level2">
<h2 class="anchored" data-anchor-id="langgraph-your-toolkit-for-context-engineering">LangGraph: Your Toolkit for Context Engineering</h2>
<p>Having established the critical role of context engineering in our previous <a href="https://neuralware.github.io/posts/context-engineering-part-1/">post</a>, let’s delve into how LangGraph provides the architectural framework to implement these principles effectively.</p>
<section id="why-langgraph-excels-at-context-engineering" class="level3">
<h3 class="anchored" data-anchor-id="why-langgraph-excels-at-context-engineering">Why LangGraph Excels at Context Engineering</h3>
<p>LangGraph’s design inherently makes it an exceptional tool for context engineering:</p>
<ul>
<li><p><strong>Explicit Control over Information Flow:</strong> The graph-based structure forces you to explicitly define how information (context) flows between different components of your application. You decide precisely what information enters each node and what information is passed on to the next. This eliminates implicit dependencies and makes context management transparent.</p></li>
<li><p><strong>Facilitates Complex, Multi-Step Reasoning:</strong> Many real-world tasks require more than a single LLM call. They involve multiple steps of reasoning, tool use, and information synthesis. LangGraph allows you to orchestrate these complex sequences, ensuring that the context is meticulously managed at each stage. For example, an agent might first retrieve documents, then summarise them, then use the summary to answer a question, and finally, if needed, perform a follow-up search – all while maintaining a consistent and evolving context.</p></li>
<li><p><strong>Supports Multi-Agent Workflows:</strong> LangGraph is particularly well-suited for building multi-agent systems, where different specialised agents collaborate to achieve a common goal. In such systems, agents often need to share and update a common context. LangGraph’s shared state mechanism and routing capabilities make it straightforward for agents to pass information back and forth, ensuring that each agent has the necessary context to perform its specific role effectively.</p></li>
</ul>
<p>In the next section, we will explore practical examples that demonstrate how these LangGraph concepts translate into robust context engineering solutions for common LLM application patterns.</p>
</section>
</section>
<section id="practical-examples-of-context-engineering-with-langgraph" class="level2">
<h2 class="anchored" data-anchor-id="practical-examples-of-context-engineering-with-langgraph">Practical Examples of Context Engineering with LangGraph</h2>
<p>Now, let’s dive into practical examples to illustrate how LangGraph facilitates robust context engineering. For these examples, we will use <code>langchain</code> and <code>langgraph</code>. Make sure you have these libraries installed (<code>pip install langchain langchain-openai langgraph</code>) and have your OpenAI API key set as an environment variable (<code>OPENAI_API_KEY</code>).</p>
<section id="stateful-ai-assitant" class="level3">
<h3 class="anchored" data-anchor-id="stateful-ai-assitant">Stateful AI Assitant</h3>
<p><strong>Problem:</strong> A common challenge in building conversational AI is maintaining context across multiple turns. A basic LLM call is stateless, meaning it forgets previous interactions. Furthermore, an AI Assistant often needs to access external information (e.g., current time, weather) to provide relevant responses.</p>
<p><strong>Context Engineering Solution with LangGraph:</strong> We can design a LangGraph application that maintains conversation history in its state and dynamically decides whether to use a tool based on the user’s query. The state will hold the chat history, which is crucial context for the LLM.</p>
<p><strong>Conceptual Flow:</strong></p>
<ol type="1">
<li>User Input: The user sends a message.</li>
<li>LLM Call (with History): The LLM receives the current message along with the accumulated conversation history.</li>
<li>Conditional Edge (Tool Decision): The LLM decides if an external tool (e.g., a search tool) is needed to answer the query.</li>
<li>Tool Call (if needed): If a tool is required, it’s invoked, and its output is added to the context.</li>
<li>LLM Call (with Tool Output): The LLM receives the original query, history, and now the tool’s output to formulate a final response.</li>
<li>Response: The LLM generates the final answer.</li>
</ol>
<p>Let’s implement a simplified version of this, focusing on maintaining history and a basic tool call.</p>
<div class="sourceCode" id="annotated-cell-1" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> operator</span>
<span id="annotated-cell-1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Annotated, Sequence, TypedDict</span>
<span id="annotated-cell-1-3"></span>
<span id="annotated-cell-1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseMessage, HumanMessage</span>
<span id="annotated-cell-1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.tools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tool</span>
<span id="annotated-cell-1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatOpenAI</span>
<span id="annotated-cell-1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StateGraph, END</span>
<span id="annotated-cell-1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.prebuilt <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ToolNode</span>
<span id="annotated-cell-1-9"></span>
<span id="annotated-cell-1-10"></span>
<span id="annotated-cell-1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Define the Graph State</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="1">1</button><span id="annotated-cell-1-12" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> AgentState(TypedDict):</span>
<span id="annotated-cell-1-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The list of messages passed between the agents</span></span>
<span id="annotated-cell-1-14">    messages: Annotated[Sequence[BaseMessage], operator.add]</span>
<span id="annotated-cell-1-15"></span>
<span id="annotated-cell-1-16"></span>
<span id="annotated-cell-1-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define a simple tool</span></span>
<span id="annotated-cell-1-18"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@tool</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="2">2</button><span id="annotated-cell-1-19" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_current_time(query: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="annotated-cell-1-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Returns the current time. Use this tool when asked about the current time."""</span></span>
<span id="annotated-cell-1-21">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> datetime</span>
<span id="annotated-cell-1-22"></span>
<span id="annotated-cell-1-23">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(datetime.datetime.now().strftime(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"%H:%M:%S"</span>))</span>
<span id="annotated-cell-1-24"></span>
<span id="annotated-cell-1-25"></span>
<span id="annotated-cell-1-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create tools list</span></span>
<span id="annotated-cell-1-27">tools <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [get_current_time]</span>
<span id="annotated-cell-1-28"></span>
<span id="annotated-cell-1-29"></span>
<span id="annotated-cell-1-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Define the Nodes</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="3">3</button><span id="annotated-cell-1-31" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> call_llm(state: AgentState):</span>
<span id="annotated-cell-1-32">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Node for LLM interaction with tool calling capabilities"""</span></span>
<span id="annotated-cell-1-33">    messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>]</span>
<span id="annotated-cell-1-34">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatOpenAI(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o"</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).bind_tools(tools)</span>
<span id="annotated-cell-1-35">    response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.invoke(messages)</span>
<span id="annotated-cell-1-36">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [response]}</span>
<span id="annotated-cell-1-37"></span>
<span id="annotated-cell-1-38"></span>
<span id="annotated-cell-1-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use LangGraph's built-in ToolNode for real tool execution</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="4">4</button><span id="annotated-cell-1-40" class="code-annotation-target">tool_node <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ToolNode(tools)</span>
<span id="annotated-cell-1-41"></span>
<span id="annotated-cell-1-42"></span>
<span id="annotated-cell-1-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. Define the Conditional Edge Logic</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="5">5</button><span id="annotated-cell-1-44" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> should_continue(state: AgentState):</span>
<span id="annotated-cell-1-45">    messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>]</span>
<span id="annotated-cell-1-46">    last_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> messages[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="annotated-cell-1-47">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check if the last message has tool calls</span></span>
<span id="annotated-cell-1-48">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> last_message.tool_calls:</span>
<span id="annotated-cell-1-49">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"call_tool"</span></span>
<span id="annotated-cell-1-50">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"end"</span></span>
<span id="annotated-cell-1-51"></span>
<span id="annotated-cell-1-52"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="6">6</button><span id="annotated-cell-1-53" class="code-annotation-target"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. Build the Graph</span></span>
<span id="annotated-cell-1-54">workflow <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StateGraph(AgentState)</span>
<span id="annotated-cell-1-55"></span>
<span id="annotated-cell-1-56">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llm"</span>, call_llm)</span>
<span id="annotated-cell-1-57">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, tool_node)</span>
<span id="annotated-cell-1-58"></span>
<span id="annotated-cell-1-59">workflow.set_entry_point(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llm"</span>)</span>
<span id="annotated-cell-1-60"></span>
<span id="annotated-cell-1-61"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add conditional edges based on tool calls</span></span>
<span id="annotated-cell-1-62">workflow.add_conditional_edges(</span>
<span id="annotated-cell-1-63">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llm"</span>,</span>
<span id="annotated-cell-1-64">    should_continue,</span>
<span id="annotated-cell-1-65">    {</span>
<span id="annotated-cell-1-66">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"call_tool"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>,</span>
<span id="annotated-cell-1-67">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"end"</span>: END,</span>
<span id="annotated-cell-1-68">    },</span>
<span id="annotated-cell-1-69">)</span>
<span id="annotated-cell-1-70"></span>
<span id="annotated-cell-1-71"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># After tool execution, always return to LLM to process results</span></span>
<span id="annotated-cell-1-72">workflow.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llm"</span>)</span>
<span id="annotated-cell-1-73"></span>
<span id="annotated-cell-1-74">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> workflow.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>()</span>
<span id="annotated-cell-1-75"></span>
<span id="annotated-cell-1-76"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 5. Run the AI Assistant</span></span>
<span id="annotated-cell-1-77"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">--- AI Assistant Interaction ---"</span>)</span>
<span id="annotated-cell-1-78">inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [HumanMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hello, how are you?"</span>)]}</span>
<span id="annotated-cell-1-79"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> s <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> app.stream(inputs):</span>
<span id="annotated-cell-1-80">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(s)</span>
<span id="annotated-cell-1-81"></span>
<span id="annotated-cell-1-82"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">--- AI Assistant Interaction (asking for time) ---"</span>)</span>
<span id="annotated-cell-1-83">inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [HumanMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What is the current time?"</span>)]}</span>
<span id="annotated-cell-1-84"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> s <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> app.stream(inputs):</span>
<span id="annotated-cell-1-85">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(s)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-1" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="12,14" data-code-annotation="1"><code>AgentState</code> is a <code>TypedDict</code> that defines the structure of our graph’s state. It primarily holds a <code>messages</code> list, which is crucial for maintaining conversation history. The <code>operator.add</code> annotation ensures that new messages are appended to the existing list, preserving the context.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="19,23" data-code-annotation="2"><code>get_current_time</code> tool is a simple Python function decorated with <code>@tool</code> that simulates an external capability. The LLM can be prompted to use this tool.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="31,36" data-code-annotation="3"><code>call_llm</code> node takes the current <code>messages</code> from the state, invokes the <code>ChatOpenAI</code> model, and returns the LLM’s response, which is then added back to the <code>messages</code> in the state.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="40" data-code-annotation="4"><code>tool_node</code> is responsible for executing the tool.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="44,50" data-code-annotation="5"><code>should_continue</code> conditional edge determines the next step based on the LLM’s last message. If the LLM indicates a tool call, it routes to the <code>tool_node</code>; otherwise, it routes to <code>END</code> (meaning the conversation turn is complete) or back to <code>llm</code> for further processing.</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="6">6</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="53,74" data-code-annotation="6">To construct the graph we define the nodes and then use <code>add_conditional_edges</code> to create the dynamic flow. The <code>set_entry_point</code> defines where the graph execution begins.</span>
</dd>
</dl>
<p>This example demonstrates how LangGraph uses its <code>State</code> to manage the evolving context (conversation history) and <code>Conditional Edges</code> to dynamically route the flow based on the LLM’s decision, enabling tool use. The entire interaction, including the tool’s output, becomes part of the context for subsequent LLM calls.</p>
</section>
<section id="document-qa-with-rag" class="level3">
<h3 class="anchored" data-anchor-id="document-qa-with-rag">Document Q&amp;A with RAG</h3>
<p><strong>Problem:</strong> Large Language Models have vast general knowledge, but they lack specific, up-to-date, or proprietary information contained within private documents (e.g., internal company policies, specific research papers). Directly feeding large documents into the LLM’s context window is often impractical due to token limits and can lead to the LLM getting lost in the noise.</p>
<p><strong>Context Engineering Solution with LangGraph:</strong> The solution is to implement a Retrieval Augmented Generation (RAG) pipeline. In a RAG system, we first retrieve relevant snippets of information from our documents based on the user’s query. Then, we provide these snippets as context to the LLM, along with the original query, to generate a concise and accurate answer. LangGraph is ideal for orchestrating this multi-step process.</p>
<p><strong>Conceptual Flow:</strong></p>
<ol type="1">
<li><strong>User Query</strong>: The user asks a question about the documents.</li>
<li><strong>Retriever</strong>: A retriever (e.g., a vector database) searches the document collection and finds the most relevant chunks of text.</li>
<li><strong>LLM (Generation)</strong>: The LLM receives the user’s query and the retrieved document snippets as context and generates an answer based on this information.</li>
</ol>
<p>Let’s build a simple RAG agent using LangGraph. We’ll use a simple in-memory vector store for this example.</p>
<div class="sourceCode" id="annotated-cell-2" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List, TypedDict</span>
<span id="annotated-cell-2-2"></span>
<span id="annotated-cell-2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_community.vectorstores <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> FAISS</span>
<span id="annotated-cell-2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.documents <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Document</span>
<span id="annotated-cell-2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.runnables <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RunnablePassthrough</span>
<span id="annotated-cell-2-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.prompts <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatPromptTemplate</span>
<span id="annotated-cell-2-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatOpenAI, OpenAIEmbeddings</span>
<span id="annotated-cell-2-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StateGraph, END</span>
<span id="annotated-cell-2-9"></span>
<span id="annotated-cell-2-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Define the Graph State</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="1">1</button><span id="annotated-cell-2-11" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> RagState(TypedDict):</span>
<span id="annotated-cell-2-12">    query: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="annotated-cell-2-13">    documents: List[Document]</span>
<span id="annotated-cell-2-14">    answer: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="annotated-cell-2-15"></span>
<span id="annotated-cell-2-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Set up the Retriever</span></span>
<span id="annotated-cell-2-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sample documents</span></span>
<span id="annotated-cell-2-18">texts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="annotated-cell-2-19">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LangGraph is a library for building stateful, multi-actor applications with LLMs."</span>,</span>
<span id="annotated-cell-2-20">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Context engineering is the art of providing the right information to an LLM."</span>,</span>
<span id="annotated-cell-2-21">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LangGraph makes it easy to create complex agentic workflows."</span></span>
<span id="annotated-cell-2-22">]</span>
<span id="annotated-cell-2-23">documents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [Document(page_content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>t) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> t <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> texts]</span>
<span id="annotated-cell-2-24"></span>
<span id="annotated-cell-2-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a simple in-memory vector store</span></span>
<span id="annotated-cell-2-26">embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAIEmbeddings()</span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="2">2</button><span id="annotated-cell-2-27" class="code-annotation-target">vectorstore <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> FAISS.from_documents(documents, embeddings)</span>
<span id="annotated-cell-2-28">retriever <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vectorstore.as_retriever()</span>
<span id="annotated-cell-2-29"></span>
<span id="annotated-cell-2-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. Define the Nodes</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="3">3</button><span id="annotated-cell-2-31" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> retrieve_documents(state: RagState):</span>
<span id="annotated-cell-2-32">    query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"query"</span>]</span>
<span id="annotated-cell-2-33">    retrieved_docs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> retriever.invoke(query)</span>
<span id="annotated-cell-2-34">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"documents"</span>: retrieved_docs}</span>
<span id="annotated-cell-2-35"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="4">4</button><span id="annotated-cell-2-36" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> generate_answer(state: RagState):</span>
<span id="annotated-cell-2-37">    query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"query"</span>]</span>
<span id="annotated-cell-2-38">    documents <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"documents"</span>]</span>
<span id="annotated-cell-2-39">    </span>
<span id="annotated-cell-2-40">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a prompt template</span></span>
<span id="annotated-cell-2-41">    prompt_template <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""Answer the user's question based only on the following </span></span>
<span id="annotated-cell-2-42"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    context:</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{context}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Question: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{question}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="annotated-cell-2-43">    prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatPromptTemplate.from_template(prompt_template)</span>
<span id="annotated-cell-2-44">    </span>
<span id="annotated-cell-2-45">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a chain</span></span>
<span id="annotated-cell-2-46">    llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatOpenAI(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o"</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="annotated-cell-2-47">    </span>
<span id="annotated-cell-2-48">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> format_docs(docs):</span>
<span id="annotated-cell-2-49">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>.join(doc.page_content <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> doc <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> docs)</span>
<span id="annotated-cell-2-50"></span>
<span id="annotated-cell-2-51">    rag_chain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="annotated-cell-2-52">        {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"context"</span>: retriever <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> format_docs, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>: RunnablePassthrough()}</span>
<span id="annotated-cell-2-53">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> prompt</span>
<span id="annotated-cell-2-54">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> llm</span>
<span id="annotated-cell-2-55">    )</span>
<span id="annotated-cell-2-56">    </span>
<span id="annotated-cell-2-57">    answer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rag_chain.invoke(query)</span>
<span id="annotated-cell-2-58">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answer"</span>: answer.content}</span>
<span id="annotated-cell-2-59"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-2" data-target-annotation="5">5</button><span id="annotated-cell-2-60" class="code-annotation-target"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. Build the Graph</span></span>
<span id="annotated-cell-2-61">workflow <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StateGraph(RagState)</span>
<span id="annotated-cell-2-62"></span>
<span id="annotated-cell-2-63">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"retriever"</span>, retrieve_documents)</span>
<span id="annotated-cell-2-64">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"generator"</span>, generate_answer)</span>
<span id="annotated-cell-2-65"></span>
<span id="annotated-cell-2-66">workflow.set_entry_point(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"retriever"</span>)</span>
<span id="annotated-cell-2-67">workflow.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"retriever"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"generator"</span>)</span>
<span id="annotated-cell-2-68">workflow.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"generator"</span>, END)</span>
<span id="annotated-cell-2-69"></span>
<span id="annotated-cell-2-70">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> workflow.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>()</span>
<span id="annotated-cell-2-71"></span>
<span id="annotated-cell-2-72"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 5. Run the RAG Agent</span></span>
<span id="annotated-cell-2-73"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">--- RAG Agent Interaction ---"</span>)</span>
<span id="annotated-cell-2-74">inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"query"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What is LangGraph?"</span>}</span>
<span id="annotated-cell-2-75">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> app.invoke(inputs)</span>
<span id="annotated-cell-2-76"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Query: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'query'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="annotated-cell-2-77"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Answer: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'answer'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-2" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="11,14" data-code-annotation="1">This state dictionary holds the <code>query</code>, the retrieved <code>documents</code>, and the final <code>answer</code>.</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="27" data-code-annotation="2">For retriever, we create a simple in-memory vector store using <code>FAISS</code> from a few sample documents. In a real-world application, this would likely be a more robust, persistent vector database.</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="31,34" data-code-annotation="3"><code>retrieve_documents</code> node takes the user’s <code>query</code> from the state, uses the retriever to find relevant documents, and updates the <code>documents</code> field in the state.</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="36,58" data-code-annotation="4"><code>generate_answer</code> node constructs a prompt that includes the retrieved <code>documents</code> as context. It then invokes the LLM to generate an answer based on this context and updates the <code>answer</code> field in the state.</span>
</dd>
<dt data-target-cell="annotated-cell-2" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-2" data-code-lines="60,70" data-code-annotation="5">Graph Construction: This is a simpler, linear graph. We define the nodes and then create a straightforward flow from the <code>retriever</code> to the <code>generator</code> and finally to the <code>END</code>.</span>
</dd>
</dl>
<p>This RAG example showcases how LangGraph can be used to orchestrate a multi-step data processing pipeline. The context (retrieved documents) is explicitly passed from one node to the next via the shared <code>State</code>, ensuring that the LLM has the necessary information to generate a grounded and accurate answer.</p>
</section>
<section id="multi-agent-workflow" class="level3">
<h3 class="anchored" data-anchor-id="multi-agent-workflow">Multi-Agent Workflow</h3>
<p><strong>Problem:</strong> Some tasks are too complex for a single LLM or a single agent to handle effectively. They might require different areas of expertise, or they might benefit from a divide-and-conquer approach. For example, generating a comprehensive research report might involve searching for information, analysing data, writing content, and editing the final draft.</p>
<p><strong>Context Engineering Solution with LangGraph:</strong> LangGraph is exceptionally well-suited for creating multi-agent workflows. We can define different agents as nodes in the graph and have them collaborate on a shared task. The shared <code>State</code> in LangGraph becomes the central scratchpad where agents can read the current status of the task, access the work of other agents, and contribute their own results.</p>
<p><strong>Conceptual Flow:</strong></p>
<ol type="1">
<li><strong>Orchestrator Agent:</strong> An orchestrator or manager agent receives the initial task and decomposes it into sub-tasks.</li>
<li><strong>Specialised Sub-Agents:</strong> The orchestrator routes the sub-tasks to specialised agents (e.g., a research agent, a writing agent, an editing agent).</li>
<li><strong>Shared State:</strong> The sub-agents perform their tasks and update the shared state with their results (e.g., research findings, written paragraphs, edited text).</li>
<li><strong>Synthesis:</strong> The orchestrator monitors the progress in the shared state and, once all sub-tasks are complete, synthesizes the results into a final output.</li>
</ol>
<p>Let’s create a simplified two-agent system: a <strong>Researcher Agent</strong> that finds information and a <strong>Writer Agent</strong> that uses that information to write a short paragraph.</p>
<div class="sourceCode" id="annotated-cell-3" style="background: #f1f3f5;"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List, TypedDict, Annotated</span>
<span id="annotated-cell-3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> operator</span>
<span id="annotated-cell-3-3"></span>
<span id="annotated-cell-3-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseMessage, HumanMessage, AIMessage</span>
<span id="annotated-cell-3-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.tools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tool</span>
<span id="annotated-cell-3-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatOpenAI</span>
<span id="annotated-cell-3-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StateGraph, END</span>
<span id="annotated-cell-3-8"></span>
<span id="annotated-cell-3-9"></span>
<span id="annotated-cell-3-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># A simple search tool for the researcher</span></span>
<span id="annotated-cell-3-11"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@tool</span></span>
<span id="annotated-cell-3-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> simple_search(query: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>:</span>
<span id="annotated-cell-3-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""A simple search tool that returns a predefined string for a given query."""</span></span>
<span id="annotated-cell-3-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"context engineering"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> query.lower():</span>
<span id="annotated-cell-3-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (</span>
<span id="annotated-cell-3-16">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Context engineering is the practice "</span></span>
<span id="annotated-cell-3-17">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"of designing and managing the information provided "</span></span>
<span id="annotated-cell-3-18">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"to an LLM to improve its performance."</span></span>
<span id="annotated-cell-3-19">        )</span>
<span id="annotated-cell-3-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="annotated-cell-3-21">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"No information found."</span></span>
<span id="annotated-cell-3-22"></span>
<span id="annotated-cell-3-23"></span>
<span id="annotated-cell-3-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Define the Graph State</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-3" data-target-annotation="1">1</button><span id="annotated-cell-3-25" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> MultiAgentState(TypedDict):</span>
<span id="annotated-cell-3-26">    messages: Annotated[List[BaseMessage], operator.add]</span>
<span id="annotated-cell-3-27">    sender: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="annotated-cell-3-28"></span>
<span id="annotated-cell-3-29"></span>
<span id="annotated-cell-3-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Define the Agents (as nodes)</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-3" data-target-annotation="2">2</button><span id="annotated-cell-3-31" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> researcher_agent(state: MultiAgentState):</span>
<span id="annotated-cell-3-32">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This agent's job is to use the search tool</span></span>
<span id="annotated-cell-3-33">    query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>][<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].content</span>
<span id="annotated-cell-3-34">    tool_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> simple_search.invoke(query)</span>
<span id="annotated-cell-3-35">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [AIMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tool_output)], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sender"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Researcher"</span>}</span>
<span id="annotated-cell-3-36"></span>
<span id="annotated-cell-3-37"></span>
<span id="annotated-cell-3-38"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> writer_agent(state: MultiAgentState):</span>
<span id="annotated-cell-3-39">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This agent's job is to write a paragraph based on the researcher's findings</span></span>
<span id="annotated-cell-3-40">    research_finding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>][<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].content</span>
<span id="annotated-cell-3-41">    prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="annotated-cell-3-42">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Write a short, engaging paragraph "</span></span>
<span id="annotated-cell-3-43">        <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"about the following topic: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>research_finding<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="annotated-cell-3-44">    )</span>
<span id="annotated-cell-3-45">    llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatOpenAI(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o"</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>)</span>
<span id="annotated-cell-3-46">    response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.invoke(prompt)</span>
<span id="annotated-cell-3-47">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [AIMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>response.content)], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sender"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Writer"</span>}</span>
<span id="annotated-cell-3-48"></span>
<span id="annotated-cell-3-49"></span>
<span id="annotated-cell-3-50"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. Define the Router (a conditional edge)</span></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-3" data-target-annotation="3">3</button><span id="annotated-cell-3-51" class="code-annotation-target"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> router(state: MultiAgentState):</span>
<span id="annotated-cell-3-52">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This router decides which agent to send the message to next</span></span>
<span id="annotated-cell-3-53">    sender <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sender"</span>]</span>
<span id="annotated-cell-3-54">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> sender <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Researcher"</span>:</span>
<span id="annotated-cell-3-55">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"writer"</span></span>
<span id="annotated-cell-3-56">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="annotated-cell-3-57">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"researcher"</span></span>
<span id="annotated-cell-3-58"></span>
<span id="annotated-cell-3-59"></span>
<button class="code-annotation-anchor" data-target-cell="annotated-cell-3" data-target-annotation="4">4</button><span id="annotated-cell-3-60" class="code-annotation-target"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. Build the Graph</span></span>
<span id="annotated-cell-3-61">workflow <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StateGraph(MultiAgentState)</span>
<span id="annotated-cell-3-62"></span>
<span id="annotated-cell-3-63">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"researcher"</span>, researcher_agent)</span>
<span id="annotated-cell-3-64">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"writer"</span>, writer_agent)</span>
<span id="annotated-cell-3-65"></span>
<span id="annotated-cell-3-66"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># The router will decide the first agent to call</span></span>
<span id="annotated-cell-3-67">workflow.add_conditional_edges(</span>
<span id="annotated-cell-3-68">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__start__"</span>,</span>
<span id="annotated-cell-3-69">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> state: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"researcher"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Start with the researcher</span></span>
<span id="annotated-cell-3-70">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"researcher"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"researcher"</span>},</span>
<span id="annotated-cell-3-71">)</span>
<span id="annotated-cell-3-72"></span>
<span id="annotated-cell-3-73">workflow.add_conditional_edges(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"researcher"</span>, router, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"writer"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"writer"</span>})</span>
<span id="annotated-cell-3-74"></span>
<span id="annotated-cell-3-75">workflow.add_conditional_edges(</span>
<span id="annotated-cell-3-76">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"writer"</span>,</span>
<span id="annotated-cell-3-77">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> state: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__end__"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># End after the writer</span></span>
<span id="annotated-cell-3-78">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__end__"</span>: END},</span>
<span id="annotated-cell-3-79">)</span>
<span id="annotated-cell-3-80"></span>
<span id="annotated-cell-3-81">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> workflow.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>()</span>
<span id="annotated-cell-3-82"></span>
<span id="annotated-cell-3-83"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 5. Run the Multi-Agent System</span></span>
<span id="annotated-cell-3-84"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">--- Multi-Agent System Interaction ---"</span>)</span>
<span id="annotated-cell-3-85">inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [HumanMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Tell me about context engineering"</span>)]}</span>
<span id="annotated-cell-3-86"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> s <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> app.stream(inputs):</span>
<span id="annotated-cell-3-87">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(s)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div>
<dl class="code-annotation-container-hidden code-annotation-container-grid">
<dt data-target-cell="annotated-cell-3" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-3" data-code-lines="25,27" data-code-annotation="1"><code>MultiAgentState</code> includes a <code>sender</code> field to track which agent last modified the state. This is crucial for routing.</span>
</dd>
<dt data-target-cell="annotated-cell-3" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-3" data-code-lines="31,47" data-code-annotation="2"><code>researcher_agent</code> and <code>writer_agent</code> nodes are functions that represent our two specialised agents. The researcher uses the <code>simple_search</code> tool, and the writer uses an LLM to generate text based on the researcher’s findings.</span>
</dd>
<dt data-target-cell="annotated-cell-3" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-3" data-code-lines="51,57" data-code-annotation="3"><code>router</code> Conditional Edge is a function that acts as the central orchestrator. It inspects the <code>sender</code> in the state and decides which agent should act next. In this simple case, it creates a linear handoff from the researcher to the writer.</span>
</dd>
<dt data-target-cell="annotated-cell-3" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-3" data-code-lines="60,81" data-code-annotation="4">Graph Construction: We define the agent nodes and then use conditional edges to control the flow. We start with the researcher, then the router sends the control to the writer, and finally, the workflow ends.</span>
</dd>
</dl>
<p>This multi-agent example illustrates how LangGraph can be used to build complex, collaborative systems. The shared <code>State</code> acts as the communication channel and shared memory between agents, and the routing logic allows for sophisticated orchestration. This is a powerful paradigm for tackling complex problems that benefit from multiple specialised perspectives, all underpinned by careful context engineering.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this post, we explored how LangGraph empowers context engineering through explicit control of information flow, multi-step reasoning, and seamless multi-agent collaboration. By walking through practical examples - stateful assistants, RAG pipelines, and multi-agent workflows - we’ve seen how LangGraph’s architecture makes context management transparent and scalable for real-world LLM applications.</p>
<p>In the final part of this three-part series, we will summarise the context engineering best practices.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{patel2025,
  author = {Patel, Prashant},
  title = {Context {Engineering:} {Building} {Smarter} {AI} {Agents} -
    {Part} 2/3},
  date = {2025-06-20},
  url = {https://neuralware.github.io/posts/context-engineering-part-2/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-patel2025" class="csl-entry quarto-appendix-citeas">
Patel, Prashant. 2025. <span>“Context Engineering: Building Smarter AI
Agents - Part 2/3.”</span> June 20, 2025. <a href="https://neuralware.github.io/posts/context-engineering-part-2/">https://neuralware.github.io/posts/context-engineering-part-2/</a>.
</div></div></section></div> ]]></description>
  <category>AI Agents</category>
  <category>LangGraph</category>
  <category>Context Engineering</category>
  <guid>https://neuralware.github.io/posts/context-engineering-part-2/</guid>
  <pubDate>Fri, 20 Jun 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Context Engineering: Building Smarter AI Agents - Part 1/3</title>
  <dc:creator>Prashant Patel</dc:creator>
  <link>https://neuralware.github.io/posts/context-engineering-part-1/</link>
  <description><![CDATA[ 





<p>For the past two years, I’ve been building generative AI applications for businesses - everything from straightforward workflows that automate simple tasks to sophisticated AI agents powering complex conversational experiences. Lately, I’ve noticed the term “context engineering” popping up everywhere in the AI community. I dug into what it actually means, only to realise it’s essentially what I’ve already been doing while developing agentic AI systems with frameworks like LangGraph. It turns out, the practices behind context engineering aren’t new - they’ve just finally been given a name.</p>
<p>In this post - the first in a three-part series - I’ll share a deep dive into context engineering, drawing on my experience building agentic AI applications for real-world businesses. I’ll illustrate key concepts with practical examples and walk through LangGraph code snippets to show how it naturally supports context engineering in practice. So, sit back, relax, and enjoy the read! 📖</p>
<section id="beyond-prompt-engineering-the-rise-of-context-engineering" class="level2">
<h2 class="anchored" data-anchor-id="beyond-prompt-engineering-the-rise-of-context-engineering">Beyond Prompt Engineering – The Rise of Context Engineering</h2>
<section id="the-evolution-of-llm-interaction" class="level3">
<h3 class="anchored" data-anchor-id="the-evolution-of-llm-interaction">The Evolution of LLM Interaction</h3>
<p>In the rapidly evolving landscape of Artificial Intelligence, Large Language Models (LLMs) have transitioned from being mere conversational tools to becoming the core intelligence of sophisticated, dynamic agentic systems. Initially, interacting with LLMs primarily involved crafting precise, single-turn prompts – a practice widely known as prompt engineering. This approach, while effective for specific, isolated queries, quickly revealed its limitations when faced with complex, multi-step tasks or ongoing dialogues. The need for LLMs to maintain state, interact with external tools, and engage in multi-turn reasoning led to the development of more advanced interaction paradigms.</p>
</section>
<section id="what-is-context-engineering" class="level3">
<h3 class="anchored" data-anchor-id="what-is-context-engineering">What is Context Engineering?</h3>
<p>As LLM applications grew in complexity, a new discipline emerged: <strong>Context Engineering</strong>. At its heart, context engineering is the art and science of meticulously managing the information an LLM uses to think, act, and decide. It’s about constructing dynamic systems that provide the right information and tools, in the optimal format, at precisely the right moment, to enable an LLM to accomplish a given task reliably and effectively.</p>
<p>To distinguish it from prompt engineering: while prompt engineering focuses on the user-facing input to produce a desired response, context engineering is a developer-facing discipline. It delves into the underlying architecture and data flows, ensuring that the LLM receives a comprehensive and well-structured input that goes far beyond a simple prompt. This comprehensive input, or ‘context,’ encompasses a wide array of elements, including:</p>
<ul>
<li><strong>System Instructions:</strong> High-level directives that define the LLM’s role, persona, and constraints.</li>
<li><strong>Retrieved Content:</strong> Information pulled from external knowledge bases, databases, or documents relevant to the current task.</li>
<li><strong>Tool Outputs:</strong> Results from external tools or APIs that the LLM has invoked (e.g., search results, database queries, code execution outputs).</li>
<li><strong>Conversation History:</strong> The ongoing dialogue, summarised or filtered to maintain coherence and continuity.</li>
<li><strong>External Data:</strong> Any other pertinent data points, such as user preferences, environmental variables, or real-time sensor data.</li>
</ul>
<p>In essence, context engineering acknowledges that the quality of an LLM’s output is directly proportional to the quality and relevance of the context it receives. It’s about building the intelligent scaffolding around the LLM that allows it to perform at its peak.</p>
</section>
<section id="why-is-context-engineering-crucial" class="level3">
<h3 class="anchored" data-anchor-id="why-is-context-engineering-crucial">Why is Context Engineering Crucial?</h3>
<p>The adage “garbage in, garbage out” holds particularly true for LLMs. Without relevant, precise, and well-organised context, even the most advanced LLMs can produce unreliable, irrelevant, or hallucinated outputs. Most failures observed in complex AI agents are not due to the inherent limitations of the LLM itself, but rather to what we term “context failures” – instances where the model was not provided with the necessary information to make an informed decision or generate an accurate response.</p>
<p>This is where <strong>LangGraph</strong> emerges as a pivotal framework. LangGraph, a powerful library within the LangChain ecosystem, provides developers with granular control over the flow of information and the management of context within LLM applications. By enabling the explicit definition of stateful, cyclic workflows, LangGraph allows for meticulous context engineering, ensuring that the LLM always operates with the most pertinent and up-to-date information. It transforms the abstract concept of context management into a tangible, programmable reality, paving the way for the development of truly intelligent and reliable AI agents.</p>
</section>
</section>
<section id="pillars-of-context-in-llm-applications" class="level2">
<h2 class="anchored" data-anchor-id="pillars-of-context-in-llm-applications">Pillars of Context in LLM Applications</h2>
<p>To effectively engineer context, it’s crucial to understand its multifaceted nature within LLM applications. Context is not a static entity; it’s a dynamic and evolving construct that underpins the LLM’s ability to reason and act.</p>
<section id="dynamic-and-evolving-context" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-and-evolving-context">Dynamic and Evolving Context</h3>
<p>Unlike traditional software where inputs are often fixed at the beginning of a process, the context for an LLM in an agentic system is assembled and continuously updated on the fly. As a task progresses, new information becomes available, previous actions yield results, and the LLM’s internal state evolves. This necessitates a system that can dynamically manage and update the context provided to the model.</p>
<blockquote class="blockquote">
<p>Consider a customer support chatbot. The initial context might be the user’s first query. As the conversation unfolds, the context expands to include the entire conversation history, the chatbot’s previous responses, and any information retrieved from a knowledge base or CRM system. If the user asks for an order status, the system needs to dynamically add order details to the context before querying the LLM.</p>
</blockquote>
</section>
<section id="full-contextual-coverage" class="level3">
<h3 class="anchored" data-anchor-id="full-contextual-coverage">Full Contextual Coverage</h3>
<p>It’s not enough to provide just the immediate query; for an LLM to perform optimally, it requires full contextual coverage. This means supplying all necessary information that might influence its understanding, reasoning, or generation. This includes not only the explicit user input but also implicit background information, system-level instructions, and relevant external data.</p>
<blockquote class="blockquote">
<p>For a code generation agent, full contextual coverage would involve not just the user’s request for a function, but also the project’s coding standards, existing library dependencies, relevant API documentation, and even examples of similar functions within the codebase. Omitting any of these could lead to suboptimal or incorrect code.</p>
</blockquote>
</section>
<section id="tools-and-external-information" class="level3">
<h3 class="anchored" data-anchor-id="tools-and-external-information">Tools and External Information</h3>
<p>One of the most significant advancements in LLM applications is their ability to leverage external tools and access real-time information. This capability is a cornerstone of effective context engineering, as it allows LLMs to overcome their inherent knowledge limitations (i.e., being trained on a fixed dataset) and interact with the dynamic real world. Tools can range from simple search engines and calculators to complex APIs for database interaction, code execution, or external service calls.</p>
<blockquote class="blockquote">
<p>An LLM agent tasked with planning a trip needs access to real-time flight prices, hotel availability, and weather forecasts. These pieces of information are not part of its pre-trained knowledge; they must be retrieved dynamically through external tools (e.g., flight booking APIs, weather APIs) and then integrated into the context for the LLM to process and generate a coherent travel plan.</p>
</blockquote>
</section>
<section id="memory-management-short-term-long-term" class="level3">
<h3 class="anchored" data-anchor-id="memory-management-short-term-long-term">Memory Management (Short-term &amp; Long-term)</h3>
<p>Effective context engineering relies heavily on robust memory management, which can be broadly categorised into short-term and long-term memory:</p>
<ul>
<li><strong>Short-term Memory:</strong> This refers to the immediate, transient context of an ongoing interaction. For LLMs, this often involves managing the conversation history within the model’s context window. Since context windows have limits, strategies like summarisation, truncation, or selective retention are crucial to preserve the most relevant parts of the dialogue.</li>
</ul>
<blockquote class="blockquote">
<p>In a multi-turn conversation, a chatbot might summarise the previous 10 turns into a concise paragraph to keep the LLM informed about the conversation’s trajectory without exceeding the context window limit.</p>
</blockquote>
<ul>
<li><strong>Long-term Memory:</strong> This involves persisting and retrieving information that spans across multiple sessions or is relevant to a user’s enduring preferences or past interactions. This often utilises external databases, vector stores, or knowledge graphs.</li>
</ul>
<blockquote class="blockquote">
<p>A personalised shopping assistant might store a user’s past purchases, preferred brands, and sizing information in a long-term memory system. When the user returns, this information can be retrieved and added to the context, allowing the LLM to offer highly relevant product recommendations.</p>
</blockquote>
</section>
<section id="structured-data-and-format" class="level3">
<h3 class="anchored" data-anchor-id="structured-data-and-format">Structured Data and Format</h3>
<p>The way information is presented to an LLM significantly impacts its ability to process and utilise that information. Well-organised, structured data (e.g., JSON, XML, or clearly delimited text) is far more effective than unstructured, messy data. Providing context in a consistent and predictable format reduces ambiguity and improves the LLM’s parsing and reasoning capabilities.</p>
<blockquote class="blockquote">
<p>When providing search results to an LLM, presenting them as a list of JSON objects with clear keys (e.g., <code>{"title": "...", "url": "...", "snippet": "..."}</code>) is much more effective than simply concatenating raw text. The structured format allows the LLM to easily identify and extract specific pieces of information, leading to more accurate and relevant responses.</p>
</blockquote>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In this first part of our three-part series, we’ve unpacked the foundations of context engineering - what it is, why it matters, and how it underpins the next generation of agentic AI systems. By exploring the pillars of context, from dynamic memory management to the integration of external tools and structured data, we’ve set the stage for building truly intelligent, reliable LLM applications.</p>
<p>In Part 2, we’ll dive into how LangGraph provides the architectural framework to put these principles into practice, enabling you to engineer context with precision and flexibility. Stay tuned!</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{patel2025,
  author = {Patel, Prashant},
  title = {Context {Engineering:} {Building} {Smarter} {AI} {Agents} -
    {Part} 1/3},
  date = {2025-06-13},
  url = {https://neuralware.github.io/posts/context-engineering-part-1/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-patel2025" class="csl-entry quarto-appendix-citeas">
Patel, Prashant. 2025. <span>“Context Engineering: Building Smarter AI
Agents - Part 1/3.”</span> June 13, 2025. <a href="https://neuralware.github.io/posts/context-engineering-part-1/">https://neuralware.github.io/posts/context-engineering-part-1/</a>.
</div></div></section></div> ]]></description>
  <category>AI Agents</category>
  <category>LangGraph</category>
  <category>Context Engineering</category>
  <guid>https://neuralware.github.io/posts/context-engineering-part-1/</guid>
  <pubDate>Fri, 13 Jun 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>MCP Explained: The Bridge Between AI and the Real World</title>
  <dc:creator>Prashant Patel</dc:creator>
  <link>https://neuralware.github.io/posts/langgraph-mcp/</link>
  <description><![CDATA[ 





<p>If you’ve been following AI developments lately, you’ve likely seen the term&nbsp;MCP&nbsp;(Model Control Protocol) gaining traction. But what exactly is it, and why does it matter for the future of AI?</p>
<p>In simple terms, MCP is a&nbsp;standardised way for AI models to interact with external tools and services, unlocking capabilities beyond just generating text. To understand why this is a big deal, let’s break down the problem it solves.</p>
<section id="the-limitation-ai-without-tools-is-like-a-brain-without-hands" class="level2">
<h2 class="anchored" data-anchor-id="the-limitation-ai-without-tools-is-like-a-brain-without-hands">The Limitation: AI Without Tools Is Like a Brain Without Hands</h2>
<p>At their core, large language models (LLMs) are incredibly skilled at&nbsp;predicting and generating text. Ask one to summarise an article or draft a story, and it performs impressively. But ask it to&nbsp;do&nbsp;something - like checking the weather, updating a calendar, or retrieving live data - and it falls short.</p>
<p>Why? Because&nbsp;LLMs alone can’t interact with the outside world. They’re like a brilliant mind trapped in a room with no doors - knowledgeable, but unable to act.</p>
</section>
<section id="the-first-solution-connecting-ai-to-tools" class="level2">
<h2 class="anchored" data-anchor-id="the-first-solution-connecting-ai-to-tools">The First Solution: Connecting AI to Tools</h2>
<p>To make AI truly useful, developers began linking LLMs to&nbsp;external tools&nbsp;(APIs, databases, web services, etc.). For example:</p>
<ul>
<li>A chatbot could fetch real-time stock prices by connecting to a financial API.</li>
<li>An AI assistant could schedule meetings by integrating with a calendar service.</li>
</ul>
<p>But there’s a catch:&nbsp;Every tool operates differently.</p>
<ul>
<li>A weather API expects inputs in a specific format.</li>
<li>A database might require unique authentication steps.</li>
<li>A task manager could have its own rules for creating entries.</li>
</ul>
<p>This means developers have to&nbsp;manually customise&nbsp;each connection - a tedious and fragile process. If one service updates its API, the entire integration can break.</p>
</section>
<section id="mcp-the-universal-plug-play-system-for-ai-tools" class="level2">
<h2 class="anchored" data-anchor-id="mcp-the-universal-plug-play-system-for-ai-tools">MCP: The Universal Plug &amp; Play System for AI Tools</h2>
<div id="fig-mcp-arch" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mcp-arch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://neuralware.github.io/posts/langgraph-mcp/img/mcp_overview.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mcp-arch-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: MCP Conceptual Architecture <span class="citation" data-cites="sakal2024">(Sakal 2024)</span>
</figcaption>
</figure>
</div>
<p>Today’s AI assistants struggle because every tool connection requires custom wiring. MCP changes this by becoming the&nbsp;USB-like standard&nbsp;for AI - where any compatible service can plug in and work immediately, just like devices with your MacBook using a USB-C hub a.k.a docking station (as illustrated in the conceptual arcitecture).</p>
<section id="how-mcp-actually-works" class="level3">
<h3 class="anchored" data-anchor-id="how-mcp-actually-works">How MCP Actually Works</h3>
<p>The definition of MCP as per the offical <a href="https://modelcontextprotocol.io/introduction">documentation</a> is as follows -</p>
<blockquote class="blockquote">
<p>MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.</p>
</blockquote>
<section id="the-mcp-server---usb-devices" class="level4">
<h4 class="anchored" data-anchor-id="the-mcp-server---usb-devices">The MCP Server - “USB Devices”</h4>
<ul>
<li>Each tool or service - Slack, Gmail, Calendar, local files - runs an MCP server</li>
<li>These are like USB devices: they translate their native APIs into the standard MCP format</li>
<li>Example: When the Calendar server gets a request like “list events”, it maps that to Google Calendar’s internal API and returns it in a universal format</li>
</ul>
</section>
<section id="the-mcp-client---agentic-ai-application" class="level4">
<h4 class="anchored" data-anchor-id="the-mcp-client---agentic-ai-application">The MCP Client - “Agentic AI Application”</h4>
<ul>
<li>Lives inside AI agents like Claude, Cursor, etc.</li>
<li>It’s like your MacBook: it doesn’t care what’s plugged in - as long as it follows the USB standard (the MCP protocol), it can use it immediately</li>
<li>Example: When you say “Send an email”, the MCP client routes the request through the hub to the Gmail server, without needing to know Gmail’s API details</li>
</ul>
</section>
<section id="the-mcp-protocol---usb-hub" class="level4">
<h4 class="anchored" data-anchor-id="the-mcp-protocol---usb-hub">The MCP Protocol - “USB Hub”</h4>
<p>The protocol is the hub connecting the client (AI) and servers (tools). It defines the standard interface they all speak:</p>
<ul>
<li>Uniform request formats (get_email, list_files, etc.)</li>
<li>Consistent response schemas (same field names, types)</li>
<li>Predictable error handling</li>
</ul>
<p>Once a tool implements this protocol, any AI can access it instantly - just like plugging into a USB hub.</p>
</section>
</section>
<section id="why-this-isnt-just-another-api" class="level3">
<h3 class="anchored" data-anchor-id="why-this-isnt-just-another-api">Why This Isn’t Just “Another API”</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Traditional Approach</th>
<th>MCP Approach</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Each tool needs custom code</td>
<td>Tools work immediately when installed</td>
</tr>
<tr class="even">
<td>APIs break when updated</td>
<td>Built-in version control prevents breaks</td>
</tr>
<tr class="odd">
<td>AI must learn each tool’s quirks</td>
<td>Standardized interactions eliminate guesswork</td>
</tr>
<tr class="even">
<td>Hard to combine tools</td>
<td>Tools can “automagically” work together</td>
</tr>
</tbody>
</table>
<section id="real-world-impact" class="level4">
<h4 class="anchored" data-anchor-id="real-world-impact">Real-World Impact</h4>
<p>An MCP-enabled AI could:</p>
<ol type="1">
<li>Notice your calendar shows an outdoor meeting<br>
</li>
<li>Check the weather MCP server for rain forecasts</li>
<li>Cross-reference traffic MCP server for delays</li>
<li>Propose rescheduling -&nbsp;all without pre-programmed rules</li>
</ol>
<p>This is why developers are excited: MCP isn’t just improving tools - it’s creating an ecosystem where AI can truly&nbsp;<em>understand</em>&nbsp;and&nbsp;<em>use</em>&nbsp;services as flexibly as humans do.</p>
</section>
</section>
</section>
<section id="why-this-matters-for-ais-future" class="level2">
<h2 class="anchored" data-anchor-id="why-this-matters-for-ais-future">Why This Matters for AI’s Future</h2>
<p>Today’s AI assistants are limited because each tool integration requires manual, brittle connections - like a smart home where every device speaks a different language and needs custom programming (no longer the case with introduction of standard Matter protocol, MCP equivalent for smart homes). MCP changes this by introducing a universal standard, enabling three key breakthroughs:</p>
<ol type="1">
<li><strong>Dynamic Tool Discovery</strong> - Instead of hard-coding every API, AI systems can automatically discover and use new MCP-compatible tools, much like plug-and-play USB devices.<br>
</li>
<li><strong>Self-Healing Connections</strong> - Unlike current systems that break when APIs update, MCP builds in versioning and fallback methods, keeping workflows intact.<br>
</li>
<li><strong>Multi-Tool Reasoning</strong> - Today, chaining actions across services (e.g., checking traffic, rescheduling meetings, and notifying teams) requires months of custom development. With MCP, AI can dynamically combine any compliant tools on the fly, enabling complex, cross-platform automation without pre-built pipelines.</li>
</ol>
<p>This shift turns AI from a tool that merely responds into a system that orchestrates - seamlessly blending services the way humans intuitively combine tools to solve problems. The result? Assistants that don’t just follow instructions but proactively adapt to real-world complexity.</p>
</section>
<section id="mcp-in-practice-building-an-ai-agent-with-model-control-protocol" class="level2">
<h2 class="anchored" data-anchor-id="mcp-in-practice-building-an-ai-agent-with-model-control-protocol">MCP in Practice: Building an AI Agent with Model Control Protocol</h2>
<p>Now that we understand MCP’s conceptual framework, let’s examine how it works in practice through a concrete implementation. We’ll explore a simple math-solving AI agent that connects to MCP-enabled tools.</p>
<section id="anatomy-of-an-mcp-system" class="level3">
<h3 class="anchored" data-anchor-id="anatomy-of-an-mcp-system">Anatomy of an MCP System</h3>
<p>Our example consists of two core components:</p>
<ol type="1">
<li>MCP Server: The “tool provider” that exposes mathematical operations</li>
<li>MCP Client: The AI agent that leverages these tools dynamically</li>
</ol>
<section id="the-mcp-server-math-as-a-service" class="level4">
<h4 class="anchored" data-anchor-id="the-mcp-server-math-as-a-service">The MCP Server: Math as a Service 🪿</h4>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mcp.server.fastmcp <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> FastMCP</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mcp_server.tools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math_tools</span>
<span id="cb1-3"></span>
<span id="cb1-4">mcp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> FastMCP(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"MCP Server"</span>)</span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Register tools with MCP instance using decorators dynamically</span></span>
<span id="cb1-7">mcp.tool()(math_tools.add)</span>
<span id="cb1-8">mcp.tool()(math_tools.multiply)</span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__main__"</span>:</span>
<span id="cb1-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb1-12">        mcp.run(transport<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"streamable-http"</span>)</span>
<span id="cb1-13">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Started MCP server"</span>)</span>
<span id="cb1-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">KeyboardInterrupt</span>:</span>
<span id="cb1-15">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Exiting..."</span>)</span>
<span id="cb1-16">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">Exception</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> e:</span>
<span id="cb1-17">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Failed to start MCP Server - </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>e<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<blockquote class="blockquote">
<p>The code uses official <code>mcp</code> python-sdk to implement a MCP Server. The repo comes with more examples in README.</p>
</blockquote>
<p>Key features worth noting:</p>
<ol type="1">
<li>Declarative Tool Registration: Tools are added using simple decorators (<code>@mcp.tool()</code>)</li>
<li>Transport Agnostic: The server can use different communication protocols (here using HTTP streaming)</li>
<li>Modular Design: Tools are organized in separate modules (tools/math_tools.py), enabling clean separation of concerns and clean extensibility.</li>
</ol>
<p>The server exposes two basic operations - addition and multiplication - but could easily scale to include hundreds of tools with the same lightweight pattern.</p>
</section>
<section id="the-mcp-client-ai-that-just-knows-how-to-use-tools" class="level4">
<h4 class="anchored" data-anchor-id="the-mcp-client-ai-that-just-knows-how-to-use-tools">The MCP Client: AI That “Just Knows” How to Use Tools 🧠</h4>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> asyncio</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_mcp_adapters.client <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MultiServerMCPClient</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.prebuilt <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> create_react_agent</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> HumanMessage</span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">async</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> main():</span>
<span id="cb2-7">    client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultiServerMCPClient({</span>
<span id="cb2-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"math"</span>: {</span>
<span id="cb2-9">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"url"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"http://localhost:8000/mcp"</span>,</span>
<span id="cb2-10">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"transport"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"streamable_http"</span>,</span>
<span id="cb2-11">        }</span>
<span id="cb2-12">    })</span>
<span id="cb2-13"></span>
<span id="cb2-14">    tools <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">await</span> client.get_tools()</span>
<span id="cb2-15">    agent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> create_react_agent(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai:gpt-4.1"</span>, tools)</span>
<span id="cb2-16"></span>
<span id="cb2-17">    response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">await</span> agent.ainvoke({</span>
<span id="cb2-18">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [HumanMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"what's (3 + 5) * 12?"</span>)]</span>
<span id="cb2-19">    })</span>
<span id="cb2-20"></span>
<span id="cb2-21">    response[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>][<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].pretty_print()</span>
<span id="cb2-22"></span>
<span id="cb2-23"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__main__"</span>:</span>
<span id="cb2-24">    asyncio.run(main())</span></code></pre></div>
<blockquote class="blockquote">
<p>We are using LangGraph to demonstrate client, but it would work with any Agent framework.</p>
</blockquote>
<p>Key features worth noting:</p>
<ol type="1">
<li>Automatic Tool Discovery: The client dynamically fetches available tools from the server</li>
<li>Zero Tool-Specific Code: The AI understands how to use add and multiply without explicit programming</li>
<li>Natural Language Interface: The operation (3 + 5) * 12 is solved through conversational interaction</li>
</ol>
<p>When executed, this agent will:</p>
<ol type="1">
<li>Parse the user’s math question</li>
<li>Determine it needs to first add 3 and 5</li>
<li>Then multiply the result by 12</li>
<li>Return the correct answer (96) - all by dynamically composing the available MCP tools</li>
</ol>
</section>
</section>
</section>
<section id="from-math-to-real-world-applications" class="level2">
<h2 class="anchored" data-anchor-id="from-math-to-real-world-applications">From Math to Real-World Applications</h2>
<p>While our example uses simple math operations, the same pattern scales to enterprise use cases:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Hypothetical enterprise MCP server</span></span>
<span id="cb3-2">mcp.tool()(salesforce.get_opportunities)</span>
<span id="cb3-3">mcp.tool()(jira.create_ticket)</span>
<span id="cb3-4">mcp.tool()(slack.send_message)</span>
<span id="cb3-5">mcp.tool()(bigquery.run_query)</span></code></pre></div>
<p>An AI agent with access to these tools could:</p>
<ul>
<li>Query Salesforce for new deals</li>
<li>Create Jira tickets for follow-ups</li>
<li>Notify teams via Slack</li>
<li>Log actions in BigQuery</li>
</ul>
<p>All through natural language requests, with no pre-built workflows.</p>
</section>
<section id="do-i-need-mcp-server-for-my-project" class="level2">
<h2 class="anchored" data-anchor-id="do-i-need-mcp-server-for-my-project">Do I need MCP Server for my Project?</h2>
<p>⭕ Are you building an Agentic AI Application with tools?<br>
⭕ Is any tool calling an internal/external API?<br>
⭕ Do you manage multiple, ever-changing APIs?<br>
⭕ Should your AI dynamically combine tools?<br>
⭕ Will you add more tools over time?</p>
<p>If you answered <strong>YES</strong> to 2 or more questions, MCP will save you time, reduce fragility, and future-proof your AI stack.</p>
<p><strong>Next Steps</strong></p>
<ol type="1">
<li>Start small: Pick one high-impact tool and MCP-enable it.</li>
<li>Use the checklist above to justify MCP adoption to your team.</li>
<li>Monitor ROI: Track reduced dev hours and increased AI capabilities post-MCP.</li>
</ol>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-sakal2024" class="csl-entry">
Sakal, Norah. 2024. <span>“MCP Vs API: Model Context Protocol Explained.”</span> 2024. <a href="https://norahsakal.com/blog/mcp-vs-api-model-context-protocol-explained/">https://norahsakal.com/blog/mcp-vs-api-model-context-protocol-explained/</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{patel2025,
  author = {Patel, Prashant},
  title = {MCP {Explained:} {The} {Bridge} {Between} {AI} and the {Real}
    {World}},
  date = {2025-05-18},
  url = {https://neuralware.github.io/posts/langgraph-mcp/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-patel2025" class="csl-entry quarto-appendix-citeas">
Patel, Prashant. 2025. <span>“MCP Explained: The Bridge Between AI and
the Real World.”</span> May 18, 2025. <a href="https://neuralware.github.io/posts/langgraph-mcp/">https://neuralware.github.io/posts/langgraph-mcp/</a>.
</div></div></section></div> ]]></description>
  <category>MCP</category>
  <category>LangGraph</category>
  <guid>https://neuralware.github.io/posts/langgraph-mcp/</guid>
  <pubDate>Sun, 18 May 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>How LangGraph Uses Redis for Fault-Tolerant Task Execution</title>
  <dc:creator>Prashant Patel</dc:creator>
  <link>https://neuralware.github.io/posts/langgraph-redis/</link>
  <description><![CDATA[ 





<p>In <a href="https://neuralware.github.io/posts/langgraph-deployment/">How to Build and Deploy an AI Agent using LangGraph from Scratch</a>, we deployed an AI agent to a standalone container running the LangGraph server. This setup communicates with both PostgreSQL and Redis. In that architecture, PostgreSQL serves as a checkpointer - responsible for persisting agent state across interactions, allowing the agent to “remember” previous conversations.</p>
<p>However, the role of Redis may have felt less clear. It’s briefly described as a task orchestrator and a channel for streaming output, but beyond that, LangGraph’s documentation doesn’t dive deep into its purpose or inner workings.</p>
<p>One of the advantages of using open-source software is transparency - we can inspect the implementation to truly understand what’s going on under the hood. So that’s exactly what I did. <sup>1</sup></p>
<p>In this article, we’ll explore how Redis fits into the LangGraph architecture and how it plays a crucial role in enabling fault-tolerant, stateful conversational AI applications, especially when working alongside PostgreSQL and the LangGraph server.</p>
<section id="redis-in-langgraph" class="level2">
<h2 class="anchored" data-anchor-id="redis-in-langgraph">Redis in LangGraph</h2>
<p>At its core, Redis serves as LangGraph’s high-performance messaging backbone, enabling two critical capabilities:</p>
<ul>
<li>Task queuing with retry counts for fault-tolerant agent workflows</li>
<li>Real-time streaming of intermediate agent outputs</li>
</ul>
<p>Unlike traditional databases, Redis specializes in low-latency operations through its in-memory data structures. For LangGraph, this means:</p>
<ul>
<li><strong>Redis List</strong> act as FIFO queues for agent task scheduling</li>
<li><strong>Redis String and Pub/Sub</strong> for bi-directional signaling (output streaming / cancellations)</li>
<li><strong>Blocking Queues</strong> create reliable queues that survive worker crashes</li>
</ul>
<p>These concepts will be clear once we start looking into the internal working.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>By using Redis as a message broker, LangGraph decouples the components that produce runs (agents/servers) from the workers that execute them.</p>
</div>
</div>
<section id="duality" class="level3">
<h3 class="anchored" data-anchor-id="duality">Duality</h3>
<p>A key architectural advantage is Redis’ ability to function as both a queue and a broadcast system simultaneously. When your LangGraph agent processes a request:</p>
<ul>
<li>PostgreSQL persists the final state (the “what”)</li>
<li>Redis orchestrates the execution path (the “how”)</li>
</ul>
<p>This explains why LangGraph requires both databases - while PostgreSQL provides durability, Redis delivers the coordination layer that makes stateful, long-running agent workflows possible.</p>
</section>
</section>
<section id="under-the-hood" class="level2">
<h2 class="anchored" data-anchor-id="under-the-hood">Under the hood</h2>
<p>The following sequence diagram captures the key interactions and the role of Redis as a messaging and signaling layer, with Postgres as the durable run data store.</p>
<div id="fig-langgraph-redis" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-langgraph-redis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://neuralware.github.io/posts/langgraph-redis/img/langgraph_redis.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-langgraph-redis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: How LangGraph uses Redis
</figcaption>
</figure>
</div>
<section id="explanation" class="level4">
<h4 class="anchored" data-anchor-id="explanation">Explanation</h4>
<p>The Agent creates a new run by inserting it into Postgres and signals workers<sup>2</sup> via a sentinel<sup>3</sup> pushed to a Redis list.</p>
<ol type="1">
<li>The Worker blocks on Redis list (BLPOP<sup>4</sup>) waiting for a wake-up signal.</li>
<li>Upon receiving the signal, the worker fetches the actual run data from Postgres.</li>
<li>The worker executes the run asynchronously.</li>
<li>During execution, the worker streams output events via Redis PubSub to the agent.</li>
<li>If a cancellation is requested, the agent sets a cancellation flag in Redis, which is communicated to the worker via PubSub channel.</li>
<li>Upon completion, the worker updates the run status in Postgres, clears ephemeral metadata in Redis, and notifies the agent (e.g., via webhook).</li>
</ol>
</section>
</section>
<section id="crash-resilience" class="level2">
<h2 class="anchored" data-anchor-id="crash-resilience">Crash Resilience</h2>
<p>At the heart of LangGraph’s fault-tolerance lies its use of Redis lists as a <em>transactional queue</em>. This is achieved via <code>BLPOP</code> and Atomic Task Handoffs.</p>
<section id="crash-safe-task-claiming" class="level3">
<h3 class="anchored" data-anchor-id="crash-safe-task-claiming">Crash-Safe Task Claiming</h3>
<p>When a worker executes a <code>BLPOP tasks: queue 0</code> (as shown in the sequence diagram), the operation is <strong>atomic</strong><sup>5</sup>:</p>
<ul>
<li>Redis only removes the task from the list <strong>after</strong> it has been delivered to the worker.</li>
<li>If the worker crashes <strong>before</strong> processing the task, the task remains in the queue.</li>
</ul>
<p>This ensures that no task is lost due to unexpected crashes or restarts. Additionally, LangGraph sets a sensible default for concurrency control:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">N_JOBS_PER_WORKER</span> = env<span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">(</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"N_JOBS_PER_WORKER"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">,</span> cast=int, default=10<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">)</span></span></code></pre></div>
<p>Each worker will process up to 10 tasks in parallel unless configured otherwise, helping scale horizontally while keeping workloads isolated.</p>
</section>
<section id="the-sentinel-pattern" class="level3">
<h3 class="anchored" data-anchor-id="the-sentinel-pattern">The Sentinel Pattern</h3>
<p>In the diagram, you may have noticed agents pushing a sentinel - a wake-up signal - into Redis.</p>
<div id="fig-sentinel-pattern" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sentinel-pattern-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://neuralware.github.io/posts/langgraph-redis/img/sentinel-pattern.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sentinel-pattern-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The Sentinel Pattern
</figcaption>
</figure>
</div>
<p>Here’s how it works:</p>
<ul>
<li>Workers use <code>BLPOP</code> with a timeout of <code>0</code>, meaning they block indefinitely until a signal arrives.</li>
<li>This design eliminates the need for polling and ensures no messages are missed - even if a worker restarts.</li>
</ul>
<p>LangGraph also reports internal metrics periodically to help with observability:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">STATS_INTERVAL_SECS</span> = env<span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">(</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"STATS_INTERVAL_SECS"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">,</span> cast=int, default=60<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">)</span></span></code></pre></div>
<p>This allows systems to track worker health and performance at one-minute intervals by default.</p>
</section>
<section id="postgresql-as-a-fallback" class="level3">
<h3 class="anchored" data-anchor-id="postgresql-as-a-fallback">PostgreSQL as a Fallback</h3>
<p>If Redis is temporarily unavailable or restarts, LangGraph falls back to PostgreSQL via <code>Runs.next</code>, as shown in the query step of the diagram.</p>
<p>This creates a two-layered recovery mechanism:</p>
<ul>
<li><strong>Redis-first</strong> (hot path): Fast, in-memory task delivery.</li>
<li><strong>PostgreSQL</strong> (cold path): Durable, persistent task storage.</li>
</ul>
<p>This layered approach ensures resilience without sacrificing performance. LangGraph also sets an upper bound on how long a background task can run:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">BG_JOB_TIMEOUT_SECS</span> = env<span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">(</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BG_JOB_TIMEOUT_SECS"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">,</span> cast=float, default=3600<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">)</span></span></code></pre></div>
<p>This ensures that long-running or stuck jobs don’t hang forever - by default, any job exceeding 1 hour is forcefully timed out.</p>
</section>
<section id="why-this-beats-polling" class="level3">
<h3 class="anchored" data-anchor-id="why-this-beats-polling">Why This Beats Polling</h3>
<p>Polling-based systems often suffer from subtle timing issues. For instance, if a worker uses RPOP<sup>6</sup> to dequeue a task and then crashes before it begins processing, that task is effectively lost. Similarly, network hiccups or buffering delays can cause tasks to be silently dropped or missed altogether.</p>
<p>LangGraph avoids these pitfalls by using BLPOP, which blocks server-side until a task is available. This means tasks remain in Redis until they are actually handed off to a live worker. There are no polling loops, no race conditions, and no dependency on fragile network timing - just clean, atomic task delivery.</p>
</section>
</section>
<section id="putting-it-all-together" class="level2">
<h2 class="anchored" data-anchor-id="putting-it-all-together">Putting it All Together</h2>
<p>In summary, LangGraph cleverly integrates Redis not just as a simple cache, but as a core component for resilient task orchestration and real-time communication. By leveraging atomic operations like <code>BLPOP</code> for crash-safe task claiming and Pub/Sub for efficient signaling and output streaming, it builds a robust system that complements PostgreSQL’s role in state persistence. This dual-database approach allows LangGraph to deliver performant, fault-tolerant execution for complex, stateful AI agent workflows, ensuring tasks are reliably processed even amidst potential failures.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><a href="https://redis.io/glossary/redis-queue/">Redis Queue</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/concepts/platform_architecture/#how-we-use-redis">LangGraph: How we use Redis</a></li>
</ol>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>LangGraph doesn’t publish source code for <code>langgraph-storage</code>, but only wheels. So you have to install the package to view the code. The implementation is present in <code>langgraph_storage.queue</code>↩︎</p></li>
<li id="fn2"><p>Workers in this context are async tasks in Python, they have nothing to do with Redis.↩︎</p></li>
<li id="fn3"><p>A sentinel is a special placeholder or signal value used within a Redis list to notify workers - it has no actual run info. Not to be confused with Redis Sentinel (the high-availability system).↩︎</p></li>
<li id="fn4"><p>In a basic queue, if a consumer tries to dequeue a task when the queue is empty, it gets a null response and may need to poll the queue repeatedly. To avoid this, Redis provides a way to implement blocking queues. In a blocking queue, if a consumer tries to dequeue a task when the queue is empty, it is put to sleep by Redis until a task is available.↩︎</p></li>
<li id="fn5"><p>Atomic tasks means, they either complete fully or not at all↩︎</p></li>
<li id="fn6"><p>RPOP: Redis command to dequeue an element (FIFO)↩︎</p></li>
</ol>
</section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{patel2025,
  author = {Patel, Prashant},
  title = {How {LangGraph} {Uses} {Redis} for {Fault-Tolerant} {Task}
    {Execution}},
  date = {2025-05-02},
  url = {https://neuralware.github.io/posts/langgraph-redis/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-patel2025" class="csl-entry quarto-appendix-citeas">
Patel, Prashant. 2025. <span>“How LangGraph Uses Redis for
Fault-Tolerant Task Execution.”</span> May 2, 2025. <a href="https://neuralware.github.io/posts/langgraph-redis/">https://neuralware.github.io/posts/langgraph-redis/</a>.
</div></div></section></div> ]]></description>
  <category>Architecture</category>
  <category>LangGraph</category>
  <category>Redis</category>
  <guid>https://neuralware.github.io/posts/langgraph-redis/</guid>
  <pubDate>Fri, 02 May 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>How to Build and Deploy an AI Agent using LangGraph from Scratch</title>
  <dc:creator>Prashant Patel</dc:creator>
  <link>https://neuralware.github.io/posts/langgraph-deployment/</link>
  <description><![CDATA[ 





<p>Building and deploying a LangGraph AI Agent from scratch involves understanding the framework’s architecture, defining your agent’s workflow as a graph, implementing nodes and state management, and finally deploying the agent either locally or on LangGraph Cloud. Below is a detailed guide covering all these steps.</p>
<p>Before we dive-in, let’s get ourselves familiarised with some components involved in developing and deploying a LangGraph application.</p>
<section id="components" class="level2">
<h2 class="anchored" data-anchor-id="components">Components</h2>
<ul>
<li><strong>LangGraph</strong> is the foundational library enabling agent workflow creation in Python and JavaScript.</li>
<li><strong>LangGraph API</strong> wraps the graph logic, managing asynchronous tasks and state persistence, serving as the backend engine.</li>
<li><strong>LangGraph Cloud</strong> hosts the API, providing deployment, monitoring, and accessible endpoints for running graphs in production.</li>
<li><strong>LangGraph Studio</strong> is the development environment that leverages the API backend for real-time graph building and testing, usable locally or in the cloud.</li>
<li><strong>LangGraph SDK</strong> offers programmatic access to LangGraph graphs, abstracting whether the graph is local or cloud-hosted, facilitating client creation and workflow execution.</li>
</ul>
<div id="fig-components" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-components-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://neuralware.github.io/posts/langgraph-deployment/img/components.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-components-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: LangGraph Components
</figcaption>
</figure>
</div>
</section>
<section id="set-up" class="level2">
<h2 class="anchored" data-anchor-id="set-up">Set Up</h2>
<p>We’ll be building a simple Agent to demonstrate the end-to-end process. Building more sophisticated AI agents is a topic better suited for a dedicated post.</p>
<p>To start with, create a following project structure and open <code>langgraph_deployment</code> directory in your favorite code editor.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">langgraph_deployment/</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">├──src</span></span>
<span id="cb1-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   ├──chat_agent/</span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   ├── utils/</span>
<span id="cb1-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   │   ├── __init__.py</span>
<span id="cb1-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   │   ├── nodes.py   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Node functions</span></span>
<span id="cb1-7"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   │   └── state.py   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># State definitions</span></span>
<span id="cb1-8"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   ├── __init__.py</span>
<span id="cb1-9"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   │   └── agent.py       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Graph construction code</span></span>
<span id="cb1-10"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">│</span>   └── __init__.py</span>
<span id="cb1-11"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">├──</span> main.py                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># LangGraph SDK demo</span></span>
<span id="cb1-12"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">├──</span> .env                   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Environment variables (add OPENAI_API_KEY)</span></span>
<span id="cb1-13"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">├──</span> .python-version        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Python version for this project (3.11)</span></span>
<span id="cb1-14"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">└──</span> langgraph.json         <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># LangGraph API configuration</span></span></code></pre></div>
<section id="install-dependencies" class="level3">
<h3 class="anchored" data-anchor-id="install-dependencies">Install dependencies</h3>
<p>We will be using <code>uv</code> for dependency management, if you haven’t used <code>uv</code> package manager before - now is the good time to start. You can install <code>uv</code> by following instructions on their <a href="https://docs.astral.sh/uv/getting-started/installation/">official page</a>.</p>
<p>Once installed run the below commands to set up the python environment.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">uv</span> python install 3.11</span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">uv</span> init</span></code></pre></div>
<p>On successful completion of above commands, you will see <code>pyproject.toml</code> added to the project. This is uv equivalent for the <code>requirements.txt</code> for managing project dependencies and bundling the project.</p>
<p>Append following lines to <code>pyproject.toml</code>. This is so that uv recognizes the build system and can build and install your package into the project environment.</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>pyproject.toml</strong></pre>
</div>
<div class="sourceCode" id="cb3" data-filename="pyproject.toml" style="background: #f1f3f5;"><pre class="sourceCode toml code-with-copy"><code class="sourceCode toml"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[build-system]</span></span>
<span id="cb3-2"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">requires</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"setuptools&gt;=42"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"wheel"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb3-3"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">build-backend</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"setuptools.build_meta"</span></span>
<span id="cb3-4"></span>
<span id="cb3-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[tool.setuptools]</span></span>
<span id="cb3-6"><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">package-dir</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">""</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"> =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"src"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
<p>Finally, install the dependencies.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">uv</span> add <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"langchain[openai]"</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"langgraph-cli[inmem]"</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb4-2">        langgraph langgraph-api langgraph-sdk</span></code></pre></div>
</section>
</section>
<section id="build" class="level2">
<h2 class="anchored" data-anchor-id="build">Build</h2>
<p>Time to get our hands dirty (in a good way)!</p>
<p>We will create a marketing research AI assistant using OpenAI’s <code>gpt-4o</code> model. Since we won’t be using any tools or any special patterns, our graph will be simple (intentionally). Let’s start adding code to the files we created.</p>
<section id="define-the-agent-state" class="level3">
<h3 class="anchored" data-anchor-id="define-the-agent-state">Define the Agent State</h3>
<p>LangGraph uses a shared state object to pass information between nodes. Define the state using Python’s TypedDict to specify the data structure.</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>state.py</strong></pre>
</div>
<div class="sourceCode" id="cb5" data-filename="state.py" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> operator <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> add</span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Annotated, TypedDict, Any</span>
<span id="cb5-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AnyMessage</span>
<span id="cb5-4"></span>
<span id="cb5-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> State(TypedDict):</span>
<span id="cb5-6">    messages: Annotated[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[AnyMessage], add]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Accumulates messages</span></span></code></pre></div>
</div>
<p>This state holds a list of messages (e.g., user input, AI responses) that are appended to as the conversation proceeds.</p>
</section>
<section id="implement-node-functions" class="level3">
<h3 class="anchored" data-anchor-id="implement-node-functions">Implement Node Functions</h3>
<p>Nodes are the processing units of your graph. Each node is a function that takes the current state as input and returns an updated state. We will add a system message to instruct the model to follow a specific role, tone, or behavior during its execution within the node.</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>nodes.py</strong></pre>
</div>
<div class="sourceCode" id="cb6" data-filename="nodes.py" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dotenv <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dotenv</span>
<span id="cb6-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.chat_models <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> init_chat_model</span>
<span id="cb6-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SystemMessage</span>
<span id="cb6-4"></span>
<span id="cb6-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> .state <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> State</span>
<span id="cb6-6"></span>
<span id="cb6-7">_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_dotenv()</span>
<span id="cb6-8"></span>
<span id="cb6-9">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> init_chat_model(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o"</span>, model_provider<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai"</span>)</span>
<span id="cb6-10"></span>
<span id="cb6-11">instructions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb6-12">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are a Marketing Research Assistant. "</span></span>
<span id="cb6-13">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Your task is to analyze market trends, competitor strategies, "</span></span>
<span id="cb6-14">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"and customer insights. "</span></span>
<span id="cb6-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Provide concise, data-backed summaries and actionable recommendations. "</span></span>
<span id="cb6-16">)</span>
<span id="cb6-17">system_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [SystemMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>instructions)]</span>
<span id="cb6-18"></span>
<span id="cb6-19"></span>
<span id="cb6-20"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> chat(state: State) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>:</span>
<span id="cb6-21">    messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> system_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>]</span>
<span id="cb6-22">    message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.invoke(messages)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate response</span></span>
<span id="cb6-23">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [message]}  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Return updated messages</span></span></code></pre></div>
</div>
</section>
<section id="construct-the-graph-workflow" class="level3">
<h3 class="anchored" data-anchor-id="construct-the-graph-workflow">Construct the Graph Workflow</h3>
<p>Use LangGraph’s <code>StateGraph</code> to build your agent’s workflow by adding nodes and edges that define the flow of execution.</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>agent.py</strong></pre>
</div>
<div class="sourceCode" id="cb7" data-filename="agent.py" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> END, START, StateGraph</span>
<span id="cb7-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> utils.nodes <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> chat</span>
<span id="cb7-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> utils.state <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> State</span>
<span id="cb7-4"></span>
<span id="cb7-5">graph_builder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StateGraph(State)</span>
<span id="cb7-6"></span>
<span id="cb7-7">graph_builder.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chat"</span>, chat)</span>
<span id="cb7-8"></span>
<span id="cb7-9">graph_builder.add_edge(START, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chat"</span>)</span>
<span id="cb7-10">graph_builder.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chat"</span>, END)</span>
<span id="cb7-11"></span>
<span id="cb7-12">graph <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> graph_builder.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>()</span></code></pre></div>
</div>
</section>
</section>
<section id="bundle" class="level2">
<h2 class="anchored" data-anchor-id="bundle">Bundle</h2>
<p>Typically, you’d need to write a backend to expose your application as an API. However, with LangGraph, that entire step is streamlined - simply add a config file and launch the service.</p>
<section id="langgraph-api-config" class="level3">
<h3 class="anchored" data-anchor-id="langgraph-api-config">LangGraph API Config</h3>
<p>To configure the API, define the settings in <code>langgraph.json</code> by adding the following lines. The configuration is straightforward, so we won’t go into the details of each field here. However, if you’re interested in exploring advanced configuration options, you can refer to the official documentation <a href="https://langchain-ai.github.io/langgraph/concepts/application_structure/#configuration-file-concepts">here</a>.</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>langgraph.json</strong></pre>
</div>
<div class="sourceCode" id="cb8" data-filename="langgraph.json" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-2">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"graphs"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-3">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"agent"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chat_agent/agent.py:graph"</span></span>
<span id="cb8-4">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb8-5">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"env"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".env"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-6">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"python_version"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"3.11"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-7">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"dependencies"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span></span>
<span id="cb8-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"."</span></span>
<span id="cb8-9">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span></span>
<span id="cb8-10"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div>
</div>
</section>
<section id="launch-service" class="level3">
<h3 class="anchored" data-anchor-id="launch-service">Launch Service</h3>
<p>Once your configuration is in place, use the following command to bundle the application and launch it as a web service:</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">langgraph</span> dev</span></code></pre></div>
<p>This command not only generates an API with ready-to-use endpoints but also spins up a web-based chat interface (Studio UI) that makes it easy to test and debug your application in real time.</p>
<p>🚀 API: <a href="http://127.0.0.1:2024">http://127.0.0.1:2024</a><br>
🎨 Studio UI: <a href="https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024">https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024</a><br>
📚 API Docs: <a href="http://127.0.0.1:2024/docs">http://127.0.0.1:2024/docs</a></p>
</section>
</section>
<section id="deploy" class="level2">
<h2 class="anchored" data-anchor-id="deploy">Deploy</h2>
<p>At this point, we have the LangGraph server running locally. Now, it’s time to deploy it. As shown in the component diagram, there are three primary deployment options available:</p>
<ol type="1">
<li>Cloud SaaS: Deploy LangGraph Servers to LangChain’s managed cloud infrastructure.</li>
<li>Self-hosted: Host and manage the LangGraph infrastructure within your own cloud environment - either just the <a href="https://langchain-ai.github.io/langgraph/concepts/langgraph_data_plane/">data plane</a> (with LangChain maintaining the <a href="https://langchain-ai.github.io/langgraph/concepts/langgraph_control_plane/">control plane</a>), or fully self-host both for complete control.</li>
<li>Standalone container: Package the LangGraph Server as a Docker image and deploy it wherever you like - such as a Kubernetes cluster - while connecting to separately hosted Postgres and Redis instances.</li>
</ol>
<p>Each option comes with trade-offs:</p>
<ul>
<li>Option 1 requires the least setup but involves commercial licensing and vendor lock-in.</li>
<li>Option 2 demands the most effort in terms of design, setup, and ongoing management, but offers maximum control.</li>
<li>Option 3 strikes a balance, offering flexibility in deployment without full platform dependency.</li>
</ul>
<p>Although there are trade-offs either option can be selected based on your internal evaluation and convenience. We will explore the Option 3 - Standalone Container.</p>
<section id="standalone-container" class="level3">
<h3 class="anchored" data-anchor-id="standalone-container">Standalone Container</h3>
<p>LangGraph supports standalone container deployments using Docker, making it possible to run a scalable, self-managed service - ideal for deploying to environments like Kubernetes. This option is non-commercial and gives you full control over the infrastructure.</p>
<p>While we won’t be deploying to a Kubernetes cluster in this guide, we’ll simulate the setup locally using Docker to mirror the architecture shown in the diagram below. Specifically, we’ll deploy three core services:</p>
<ul>
<li>LangGraph API – the same service we configured and tested locally in the previous step.</li>
<li>PostgreSQL – used for persistent storage by LangGraph.</li>
<li>Redis – used for task orchestration and streaming output events through Pub/Sub.</li>
</ul>
<p>This local deployment will serve as a lightweight, production-like replica, allowing us to validate the architecture and interactions between components without the overhead of a full Kubernetes setup.</p>
<div id="fig-container" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-container-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://neuralware.github.io/posts/langgraph-deployment/img/standalone-container.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-container-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Standalone Container Deployment
</figcaption>
</figure>
</div>
</section>
<section id="local-deployment-with-docker-compose" class="level3">
<h3 class="anchored" data-anchor-id="local-deployment-with-docker-compose">Local Deployment with Docker Compose</h3>
<p>To simplify service orchestration, we’ll use Docker Compose to bring up the LangGraph API along with its required dependencies - PostgreSQL and Redis. This setup replicates a production-like environment locally and abstracts away the need to manage containers individually.</p>
<section id="langgraph-api" class="level4">
<h4 class="anchored" data-anchor-id="langgraph-api">LangGraph API</h4>
<p>If the application is structured correctly, you can build a docker image with the LangGraph Deploy server.</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">langgraph</span> build <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--tag</span> chat_agent:v1.0.0</span></code></pre></div>
<p>This command packages your application into a Docker image named <code>chat_agent:v1.0.0</code>, ready for deployment.</p>
</section>
<section id="docker-compose" class="level4">
<h4 class="anchored" data-anchor-id="docker-compose">Docker Compose</h4>
<p>We’ll define the services in a <code>docker-compose.yml</code> file as shown below.</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>docker-compose.yml</strong></pre>
</div>
<div class="sourceCode" id="cb11" data-filename="docker-compose.yml" style="background: #f1f3f5;"><pre class="sourceCode yml code-with-copy"><code class="sourceCode yaml"><span id="cb11-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">volumes</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-2"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">langgraph-data</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-3"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">driver</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> local</span></span>
<span id="cb11-4"></span>
<span id="cb11-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">services</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-6"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">langgraph-redis</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-7"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">image</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> redis:6</span></span>
<span id="cb11-8"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">healthcheck</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-9"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">test</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CMD"</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">,</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"redis-cli"</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">,</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ping"</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">]</span></span>
<span id="cb11-10"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">interval</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> 5s</span></span>
<span id="cb11-11"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">timeout</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> 1s</span></span>
<span id="cb11-12"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">retries</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb11-13"></span>
<span id="cb11-14"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">langgraph-postgres</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-15"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">image</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> postgres:16</span></span>
<span id="cb11-16"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ports</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-17"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">-</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"5433:5432"</span></span>
<span id="cb11-18"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">environment</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-19"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">POSTGRES_DB</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> postgres</span></span>
<span id="cb11-20"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">POSTGRES_USER</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> postgres</span></span>
<span id="cb11-21"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">POSTGRES_PASSWORD</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> postgres</span></span>
<span id="cb11-22"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">volumes</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-23"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">-</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> langgraph-data:/var/lib/postgresql/data</span></span>
<span id="cb11-24"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">healthcheck</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-25"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">test</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">[</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"CMD"</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">,</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pg_isready"</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">,</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-U"</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">,</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"postgres"</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">]</span></span>
<span id="cb11-26"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">start_period</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> 10s</span></span>
<span id="cb11-27"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">timeout</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> 1s</span></span>
<span id="cb11-28"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">retries</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb11-29"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">interval</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> 5s</span></span>
<span id="cb11-30"></span>
<span id="cb11-31"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">  </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">langgraph-api</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-32"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">image</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> ${IMAGE_NAME}</span></span>
<span id="cb11-33"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ports</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-34"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">-</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> </span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"8123:8000"</span></span>
<span id="cb11-35"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">depends_on</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-36"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">langgraph-redis</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-37"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">        </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">condition</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> service_healthy</span></span>
<span id="cb11-38"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">langgraph-postgres</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-39"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">        </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">condition</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> service_healthy</span></span>
<span id="cb11-40"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">env_file</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-41"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">-</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> .env</span></span>
<span id="cb11-42"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">    </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">environment</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span></span>
<span id="cb11-43"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">REDIS_URI</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> redis://langgraph-redis:6379</span></span>
<span id="cb11-44"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">LANGSMITH_API_KEY</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> ${LANGSMITH_API_KEY}</span></span>
<span id="cb11-45"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">      </span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">POSTGRES_URI</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">:</span><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;"> postgres://postgres:postgres@langgraph-postgres:5432/postgres?sslmode=disable</span></span></code></pre></div>
</div>
</section>
<section id="running-the-application" class="level4">
<h4 class="anchored" data-anchor-id="running-the-application">Running the Application</h4>
<p>Ensure that your .env file includes valid values for <code>IMAGE_NAME</code> and <code>LANGSMITH_API_KEY</code> before running the Docker Compose setup.</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>.env</strong></pre>
</div>
<div class="sourceCode" id="cb12" data-filename=".env" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">OPENAI_API_KEY</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>your-openai-api-key</span>
<span id="cb12-2"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">LANGSMITH_API_KEY</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>your-langsmith-api-key</span>
<span id="cb12-3"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">IMAGE_NAME</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>chat_agent:v1.0.0</span></code></pre></div>
</div>
<p>Once everything is set, start the stack by running:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">docker</span> compose up <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--build</span></span></code></pre></div>
<p>This will -</p>
<ul>
<li>Start and link the required Redis and PostgreSQL containers</li>
<li>Build and launch your LangGraph API container</li>
<li>Wait for dependent services to become healthy before launching the API</li>
<li>Expose the API locally at http://localhost:8123</li>
</ul>
<p>You can test that the application is up by checking:</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb14-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">curl</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--request</span> GET <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--url</span> 0.0.0.0:8123/ok</span></code></pre></div>
<p>Assuming everything is running correctly, you should see a response like:</p>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode sh code-with-copy"><code class="sourceCode bash"><span id="cb15-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ok"</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">:true}</span></span></code></pre></div>
</section>
</section>
</section>
<section id="interact" class="level2">
<h2 class="anchored" data-anchor-id="interact">Interact</h2>
<p>If you’ve made it this far - congratulations! 🎉</p>
<p>The final step is to interact with your deployed LangGraph server using the LangGraph SDK.</p>
<p>LangGraph provides SDKs for both <a href="https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/">Python</a> and <a href="https://langchain-ai.github.io/langgraph/cloud/reference/sdk/js_ts_sdk_ref/">JavaScript/TypeScript</a>, making it easy to work with deployed graphs - whether hosted locally or in the cloud. The SDK abstracts away the complexity of direct API calls and provides:</p>
<ul>
<li>A unified interface to connect with LangGraph graphs</li>
<li>Easy access to assistants and conversation threads</li>
<li>Simple run execution and real-time streaming capabilities</li>
</ul>
<p>Following is the code-snippet in Python to demonstrate interaction with the graph we deployed in the previous step -</p>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>main.py</strong></pre>
</div>
<div class="sourceCode" id="cb16" data-filename="main.py" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> asyncio</span>
<span id="cb16-2"></span>
<span id="cb16-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> HumanMessage</span>
<span id="cb16-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph_sdk <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> get_client</span>
<span id="cb16-5"></span>
<span id="cb16-6">LANGGRAPH_SERVER_URL <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"http://localhost:8123"</span></span>
<span id="cb16-7"></span>
<span id="cb16-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">async</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> main() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb16-9"></span>
<span id="cb16-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the LangGraph client</span></span>
<span id="cb16-11">    client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_client(url<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>LANGGRAPH_SERVER_URL)</span>
<span id="cb16-12"></span>
<span id="cb16-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fetch the list of available assistants from the server</span></span>
<span id="cb16-14">    assistants <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">await</span> client.assistants.search()</span>
<span id="cb16-15"></span>
<span id="cb16-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Select the first assistant from the list</span></span>
<span id="cb16-17">    agent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> assistants[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb16-18"></span>
<span id="cb16-19">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new conversation thread with the assistant</span></span>
<span id="cb16-20">    thread <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">await</span> client.threads.create()</span>
<span id="cb16-21"></span>
<span id="cb16-22">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare the user message</span></span>
<span id="cb16-23">    user_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [HumanMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hi"</span>)]}</span>
<span id="cb16-24"></span>
<span id="cb16-25">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Stream the assistant's response in real-time</span></span>
<span id="cb16-26">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">async</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> chunk <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> client.runs.stream(</span>
<span id="cb16-27">        thread_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>thread[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"thread_id"</span>],</span>
<span id="cb16-28">        assistant_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>agent[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"assistant_id"</span>],</span>
<span id="cb16-29">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>user_message,</span>
<span id="cb16-30">        stream_mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"values"</span>,</span>
<span id="cb16-31">    ):</span>
<span id="cb16-32">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Filter out metadata events and empty data chunks</span></span>
<span id="cb16-33">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> chunk.data <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> chunk.event <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"metadata"</span>:</span>
<span id="cb16-34">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Print the content of latest assistant message</span></span>
<span id="cb16-35">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(chunk.data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>][<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>])</span>
<span id="cb16-36"></span>
<span id="cb16-37"></span>
<span id="cb16-38"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__main__"</span>:</span>
<span id="cb16-39">    asyncio.run(main())</span></code></pre></div>
</div>
<p>The above code is intuitive, so I’ll leave it to you to run and explore.</p>
<p>At first glance, the response you get might feel modest - a simple message in return for a simple prompt. But behind that is a clean, scalable setup that mirrors how production-grade AI systems are built. You’ve laid the groundwork for something much bigger. Swapping out this basic agent for a more advanced one is just a matter of choice now. So while it might not feel flashy, make no mistake - you’ve just put a serious system in place.</p>
<blockquote class="blockquote">
<p><strong>Want to take this further?</strong> Try integrating it into a Streamlit frontend to create an interactive, real-time chat experience.</p>
</blockquote>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<ol type="1">
<li><a href="https://langchain-ai.github.io/langgraph/cloud/deployment/cloud/">How to Deploy to Cloud SaaS</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/concepts/langgraph_self_hosted_data_plane/">Self-Hosted Data Plane</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/concepts/langgraph_self_hosted_control_plane/">Self-Hosted Control Plane</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/how-tos/auth/custom_auth/">How to add custom authentication</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/how-tos/http/custom_routes/">How to add custom routes</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/cloud/how-tos/use_stream_react/">How to integrate LangGraph into your React application</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/concepts/sdk/">LangGraph SDK</a></li>
</ol>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><a href="https://langchain-ai.github.io/langgraph/tutorials/deployment/#deployment-options">LangGraph Deployment Options</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/how-tos/deploy-self-hosted/">How to do a Self-hosted deployment of LangGraph</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/cloud/deployment/standalone_container/">How to Deploy a Standalone Container</a></li>
</ol>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{patel2025,
  author = {Patel, Prashant},
  title = {How to {Build} and {Deploy} an {AI} {Agent} Using {LangGraph}
    from {Scratch}},
  date = {2025-04-25},
  url = {https://neuralware.github.io/posts/langgraph-deployment/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-patel2025" class="csl-entry quarto-appendix-citeas">
Patel, Prashant. 2025. <span>“How to Build and Deploy an AI Agent Using
LangGraph from Scratch.”</span> April 25, 2025. <a href="https://neuralware.github.io/posts/langgraph-deployment/">https://neuralware.github.io/posts/langgraph-deployment/</a>.
</div></div></section></div> ]]></description>
  <category>AI Agents</category>
  <category>Deployment</category>
  <category>LangGraph</category>
  <guid>https://neuralware.github.io/posts/langgraph-deployment/</guid>
  <pubDate>Fri, 25 Apr 2025 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
